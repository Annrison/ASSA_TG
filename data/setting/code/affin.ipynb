{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2cf467-4645-45df-9c5f-4575ee085ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a70f7a7-8fda-4996-8f49-e20cf01e3a00",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../seed/sen_seed_25.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f1a135f0177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../seed/sen_seed_25.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_pos_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../seed/sen_seed_25.txt'"
     ]
    }
   ],
   "source": [
    "with open('../seed/sen_seed_25.txt') as f:\n",
    "    lines = f.read()        \n",
    "seeds = lines.split(\"|\")    \n",
    "N = 5\n",
    "train_pos_word = seeds[0].split(\" \")[:N]\n",
    "train_neg_word = seeds[1].split(\" \")[:N]\n",
    "all_train_word = train_pos_word + train_neg_word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de245fd9-cbf3-405f-b8ef-2cdddecabac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad', 'disappointed', 'wrong', 'terrible', 'worst']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce4265a-7452-4a84-8c80-813ee504e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'YELP'\n",
    "corpus_type = 'sent'\n",
    "train_name = f\"{dataset}_{corpus_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5363773e-71c2-41c5-a09a-79021700d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv(f'../../preprocessed/{dataset}/{train_name}_5w.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1192699-2055-405d-b3e9-9b275f3516b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "affin = pd.read_csv('dict/afinn.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4308ba-c251-4bd6-ae80-4d37ee5ae616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>sentence</th>\n",
       "      <th>scode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yet another five star review for this fantasti...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>yet another five_star review for this fantasti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  len  \\\n",
       "0  Yet another five star review for this fantasti...  9.0   \n",
       "\n",
       "                                            sentence  scode  \n",
       "0  yet another five_star review for this fantasti...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb00a2-7845-4e29-80d9-04d0fd117b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a89b9e2b-c659-4bcf-a16b-12dc8613ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read corpus\n",
    "lines = corpus_df.sentence.tolist()\n",
    "word_l = [i.split() for i in lines]\n",
    "word_l = [x for xs in word_l for x in xs]\n",
    "\n",
    "# word count\n",
    "word_df = pd.DataFrame(word_l,columns =['word'])\n",
    "merge = word_df.merge(affin,how='inner',on='word')\n",
    "count = merge.groupby(['word']).size().reset_index(name='count')\n",
    "count_value = count.merge(affin,how='left',on='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1fcb3-ff61-4e0b-9448-b7b9eea890cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ea56d4f-1387-4c56-bc0f-bce095d75268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = [\"good\", \"great\", \"nice\", \"best\", \"amazing\"]\n",
    "# nl = [\"gross\", \"bad\", \"terrible\", \"hate\", \"disappointed\"]\n",
    "# 看一下之前的字都是多少分\n",
    "# count_value[count_value['word'].isin(pl)]\n",
    "# 看一下之前的字都是多少分\n",
    "# count_value[count_value['word'].isin(nl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1cfaae-b663-459a-9696-bf850952e08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "196f8bc2-db29-4c25-81c1-c1725f59ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用詞頻來看，選最多的五個\n",
    "# 但正面情緒值要大於三\n",
    "pos_df = count_value[count_value['value']>=3]\n",
    "pos_df = pos_df.sort_values(['count', 'value'],ascending = [False, True])\n",
    "neg_df = count_value[count_value['value']<=-2]\n",
    "neg_df = neg_df.sort_values(['count', 'value'],ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32ab8ce8-ecd4-44bf-a5a8-76c01926abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_n(top_n, pos, neg):\n",
    "    pos_word_seed = pos.head(top_n).word.tolist()\n",
    "    neg_word_seed = neg.head(top_n).word.tolist()\n",
    "    return pos_word_seed, neg_word_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b07c820-47c4-4ef0-b9e3-1c5fcfdd6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_txt(fname, pos_l,neg_l):\n",
    "    both = ' '.join(pos_l) + '|' + ' '.join(neg_l)\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write(\"%s\" % both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63315f5b-0808-4e79-8dca-b87907083772",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_25 = select_top_n(25, pos_df, neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14a389d9-e1f5-45e9-b6a4-e6693e0158a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_25[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c6c925c-3712-4bb2-996a-6ef99fea5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_txt(f'affin_gen_{train_name}.txt',seed_25[0], seed_25[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3cad6f2-07bc-499c-8388-dea7c906bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查一下讀取有沒有問題，可以的話就放去seed那層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5184aa9d-4f11-4868-a381-23a464e23aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "with open(f'affin_gen_{train_name}.txt') as f:\n",
    "    lines = f.read()\n",
    "    \n",
    "seeds = lines.split(\"|\")\n",
    "pos_word = seeds[0].split(\" \")[:N]\n",
    "neg_word = seeds[1].split(\" \")[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cb914d0-addc-4edb-b48b-c39caf920508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'great',\n",
       " 'love',\n",
       " 'best',\n",
       " 'nice',\n",
       " 'excellent',\n",
       " 'awesome',\n",
       " 'perfect',\n",
       " 'super',\n",
       " 'amazing']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50a5266-4296-460e-85da-bb43c93cbf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'great',\n",
       " 'love',\n",
       " 'nice',\n",
       " 'best',\n",
       " 'happy',\n",
       " 'perfect',\n",
       " 'fan',\n",
       " 'excellent',\n",
       " 'awesome']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aff411-48f2-4e42-a9b4-6e2a5866b96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
